#import feature selection methods
from sklearn.feature_selection import f_classif, chi2, mutual_info_classif
from boruta import BorutaPy

from sklearn.ensemble import RandomForestClassifier

from statistics import mean, median
import pandas as pd
import numpy as np
import argparse
import os

def writeFeaturesToFile(file, featurelst):
    try:
        handle = open(file, "w")
    except Exception as error:
        print(f"Could not write file {error}")
        return

    for feature in featurelst:
        feature += '\n'
        handle.write(feature)
    handle.close()

# Main execution starts from here. Get user arguments and process classifiers.
parser = argparse.ArgumentParser("Apply feature selection models to feature set")
parser.add_argument('path', help="Path to dataset file")

userArgs = parser.parse_args()
path = userArgs.path

if not os.path.isfile(path):
    print("Path is not a csv file")
    exit(2)

dataframe = pd.read_csv(path, delimiter=',')
training = pd.DataFrame(dataframe)

#drop the class column from training set
x = training.drop(['class'], axis = 1)
# use the class colum as the target classification label
y = training['class']


#Feature Selection methods START
#chi2_score, chi_2_p_value = chi2(x,y)
f_score, f_p_value = f_classif(x, y)
mut_info_score = mutual_info_classif(x, y)

#print('chi2 score        ', chi2_score)
#chi_pval_count = len([val for val in chi_2_p_value if val > 0.05])
#print(f"chi2 p-value > 0.05:  {chi_pval_count}")

#create a list of seected feature where p value is greater than 0.05
f_pval_list = []
#print('F - score score   ', f_score)
for idx in range(len(f_p_value)):
    if (f_p_value[idx] > 0.05):
        f_pval_list.append(x.columns.values[idx])
f_pval_count = len([val for val in f_p_value if val > 0.05])
print(f"ftest p-value > 0.05: {f_pval_count}, {len(f_pval_list)}")
f_pval_list.append('class')
fval_dataset = training.filter(f_pval_list, axis=1)
fval_dataset.to_csv("D:\\fval_ml_input.csv", index=False, encoding='utf-8')

mut_info_max = max(mut_info_score)
mut_info_min = min(mut_info_score)
mut_info_thresh = (mut_info_min + mut_info_max)/2

#select ones greater than mean
print(f"mutual info threshold = {mut_info_thresh}")
mut_info_list = []
for idx in range(len(mut_info_score)):
    if(mut_info_score[idx] > mut_info_thresh):
        mut_info_list.append(x.columns.values[idx])
mut_info_count = len([val for val in mut_info_score if val > mut_info_thresh])
print(f"mutual info  > threshold: {mut_info_count}, {len(mut_info_list)}")
mut_info_list.append('class')
infogain_dataset = training.filter(mut_info_list, axis=1)
infogain_dataset.to_csv("D:\\infogain_ml_input.csv", index=False, encoding='utf-8')

#Boruta feature section on the training set
rfc = RandomForestClassifier(random_state=1, n_estimators=1000, max_depth=5)
boruta_selector = BorutaPy(rfc, n_estimators='auto', verbose=2, random_state=1)
boruta_selector.fit(np.array(x), np.array(y))
print("Ranking: ",boruta_selector.ranking_)
print("No. of significant features: ", boruta_selector.n_features_)

boruta_feat_lst = []
for idx in range(len(boruta_selector.support_)):
    if (boruta_selector.support_[idx]):
        boruta_feat_lst.append(x.columns[idx])
boruta_feat_lst.append('class')
boruta_dataset = training.filter(boruta_feat_lst, axis=1)

boruta_dataset.to_csv("D:\\boruta_ml_input.csv", index=False, encoding='utf-8')